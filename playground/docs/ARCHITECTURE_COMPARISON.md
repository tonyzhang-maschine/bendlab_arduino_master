# Architecture Comparison: Original vs Multiprocessing

## Quick Summary

**Original (`jq_glove_capture.py`)**: Simple single-process script for data exploration
**New (`acquisition_process.py`)**: Production-ready multiprocessing architecture for real-time applications

---

## Side-by-Side Comparison

### 1. **Purpose & Use Case**

| Aspect | Original (jq_glove_capture.py) | New (acquisition_process.py) |
|--------|-------------------------------|------------------------------|
| **Purpose** | Exploration & analysis | Production real-time capture |
| **Use case** | Understand data format | GUI, logging, LSL streaming |
| **Output** | Binary file + analysis report | Live data stream via Queue |
| **Duration** | Fixed (1 second) | Continuous (until stopped) |

### 2. **Architecture**

#### Original: Single-Process, Batch-and-Analyze
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Single Python Process              â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Serial Read â”‚ (1 second)        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   Buffer    â”‚ (bytearray)       â”‚
â”‚  â”‚  all_data   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Parse ALL   â”‚ (after capture)   â”‚
â”‚  â”‚ at once     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Analyze &  â”‚                   â”‚
â”‚  â”‚  Save .bin  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### New: Multi-Process, Real-Time Streaming
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Acquisition Process (dedicated)    â”‚     â”‚  Consumer Process(es)   â”‚
â”‚  [High Priority, No GUI]            â”‚     â”‚  [GUI, Logger, LSL]     â”‚
â”‚                                     â”‚     â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚     â”‚                         â”‚
â”‚  â”‚ Serial Read â”‚ (continuous)      â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚     â”‚  â”‚ GUI Display  â”‚       â”‚
â”‚         â”‚ 8192 bytes                â”‚     â”‚  â”‚   60 Hz      â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                   â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”‚ GloveParser â”‚ (incremental)     â”‚     â”‚                         â”‚
â”‚  â”‚  add_data() â”‚                   â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚     â”‚  â”‚ HDF5 Logger  â”‚       â”‚
â”‚         â”‚ frames                    â”‚     â”‚  â”‚  200 Hz      â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                   â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”‚ Queue.put() â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–¶â”‚                         â”‚
â”‚  â”‚ (non-block) â”‚  multiprocessing  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     Queue          â”‚     â”‚  â”‚ LSL Stream   â”‚       â”‚
â”‚         â–²                            â”‚     â”‚  â”‚  200 Hz      â”‚       â”‚
â”‚         â”‚ (continues...)            â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                            â”‚     â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â””â”€ Never blocks on consumers
```

### 3. **Serial Reading Strategy**

| Aspect | Original | New |
|--------|----------|-----|
| **Read method** | `ser.read(ser.in_waiting)` | `ser.read(8192)` fixed size |
| **Timeout** | 1.0 second | 0.05 seconds (50ms) |
| **Read size** | Variable (~103 B avg) | Fixed 8192 bytes |
| **Reads/sec** | ~611 tiny reads | ~20 large reads |
| **Loop delay** | `time.sleep(0.001)` | None (blocking read) |
| **Performance** | 10-20 Hz (with parsing) | 200+ Hz |

**Why the difference?**
- Original: Optimized for capturing ALL data for offline analysis
- New: Optimized for maximum throughput with minimal latency

### 4. **Data Parsing**

| Aspect | Original | New |
|--------|----------|-----|
| **When** | After full capture (batch) | Incremental (real-time) |
| **Parser** | Custom `split_packets()` | `GloveParser` class |
| **Frame assembly** | Manual analysis | Automatic (0x01 + 0x02) |
| **Buffer** | Hold ALL data in memory | Circular buffer (200 bytes) |
| **Output** | List of packets | Stream of frames |

### 5. **Data Flow & Communication**

#### Original: In-Memory Analysis
```python
# Capture phase
all_data = bytearray()
while time.time() - start_time < CAPTURE_DURATION:
    if ser.in_waiting > 0:
        chunk = ser.read(ser.in_waiting)
        all_data.extend(chunk)  # Buffer everything
    time.sleep(0.001)

# Analysis phase (after capture)
packets = split_packets(all_data, PACKET_DELIMITER)
# ... analyze, print stats, save to file
```

#### New: Process-Safe Queue
```python
# Producer (acquisition process)
while not stop_event.is_set():
    data = serial_conn.read(8192)
    frames = parser.add_data(data)

    for frame in frames:
        frame_queue.put_nowait({
            'frame': frame,
            'timestamp': time.time(),
            'frame_number': frame_count
        })

# Consumer (GUI/logger process)
while running:
    frame_data = acq.get_frame(block=False)
    if frame_data:
        # Update GUI, log to file, stream to LSL, etc.
        visualizer.update(frame_data['frame'])
```

### 6. **Concurrency & Performance**

| Aspect | Original | New |
|--------|----------|-----|
| **Process model** | Single-threaded | Multi-process |
| **GIL limitation** | Affects everything | Bypassed (true parallelism) |
| **CPU cores used** | 1 | 2+ (acquisition + consumers) |
| **Blocking operations** | All in one process | Isolated per process |
| **GUI impact** | N/A (no GUI) | GUI doesn't slow acquisition |

**Key Benefit**: Acquisition runs at full speed regardless of consumer(s) speed!

### 7. **Error Handling & Robustness**

| Aspect | Original | New |
|--------|----------|-----|
| **Serial errors** | Crash entire script | Caught in acquisition process |
| **Queue full** | N/A | Non-blocking put (drops frame) |
| **Process crash** | Loses everything | Only one process affected |
| **Graceful shutdown** | Ctrl+C | `stop_event` + timeout |
| **Statistics** | Print at end | Real-time via stats_queue |

### 8. **Output & Data Products**

#### Original Output
```
============================================================
DATA ANALYSIS
============================================================

ğŸ“Š Total bytes captured: 67720
   Expected packets (~100Hz): ~100

ğŸ” Delimiter [AA 55 03 99] found: 476 times
âœ“ Extracted 476 packets
âœ“ Parsed 476 packets

ğŸ“‹ Packet Index Distribution:
   0x01 (  1): 238 packets
   0x02 (  2): 238 packets
...

ğŸ’¾ Data saved to: glove_data_20250128_153045.bin
```

#### New Output (Real-time)
```python
# Frame data structure
{
    'frame': np.ndarray(272, dtype=uint8),  # 272 bytes of sensor data
    'timestamp': 1706459445.123456,          # Precise timestamp
    'frame_number': 12345                    # Sequential counter
}

# Real-time statistics
{
    'frame_count': 12345,
    'elapsed_time': 61.5,
    'capture_rate_hz': 200.7,
    'queue_depth': 15,  # or -1 on macOS
    'bytes_read': 3821640
}
```

### 9. **Use Cases**

#### Original (jq_glove_capture.py)
âœ… **Good for:**
- Understanding data format
- Verifying hardware connection
- Quick data rate checks
- Debugging protocol issues
- Creating test datasets

âŒ **Not suitable for:**
- Real-time visualization
- Continuous recording
- Streaming to other systems
- Production applications

#### New (acquisition_process.py)
âœ… **Good for:**
- Real-time GUI visualization
- Continuous data logging (HDF5)
- LSL streaming to other software
- Multi-consumer scenarios
- Production deployments

âŒ **Overkill for:**
- Simple data exploration
- One-time captures
- Learning the protocol

### 10. **Code Complexity**

| Aspect | Original | New |
|--------|----------|-----|
| **Lines of code** | ~240 | ~340 |
| **Dependencies** | `serial`, `time` | `serial`, `time`, `multiprocessing`, `numpy` |
| **Complexity** | Low (linear script) | Medium (process management) |
| **Setup** | Import & run | Start/stop process lifecycle |
| **Learning curve** | Easy | Medium |

### 11. **Memory Usage**

#### Original
- **Buffer size**: Grows with capture duration
  - 1 second = ~67 KB
  - 60 seconds = ~4 MB
  - Entire capture held in RAM

#### New
- **Queue**: Fixed size (1000 frames = ~265 KB)
- **Parser buffer**: ~200 bytes
- **Per frame**: 272 bytes
- **Total**: ~300 KB steady-state
- Old frames automatically discarded

### 12. **Latency**

| Metric | Original | New |
|--------|----------|-----|
| **Data availability** | After full capture | Immediate (<50ms) |
| **Frame-to-display** | N/A | 50-100ms |
| **Analysis delay** | Seconds | Real-time |

---

## Key Innovations in New Architecture

### 1. **Fixed-Size Reads (8192 bytes)**
- **Problem**: `in_waiting` caused 611 tiny reads/sec (103 B each)
- **Solution**: Fixed 8192-byte reads â†’ 20 reads/sec (3217 B each)
- **Impact**: 80x larger reads = much less overhead

### 2. **Optimized Timeout (50ms)**
- **Problem**: 10ms timeout â†’ 99% time blocked in read
- **Solution**: 50ms timeout allows more data accumulation
- **Impact**: 2x throughput improvement

### 3. **GloveParser Buffer Fix**
- **Problem**: Kept only 3 bytes when no delimiter found
- **Solution**: Keep up to 200 bytes (max packet size + margin)
- **Impact**: Eliminated massive frame loss

### 4. **Non-Blocking Queue Operations**
- **Problem**: Don't want to slow down acquisition
- **Solution**: `put_nowait()` - drop if queue full
- **Philosophy**: Better to drop 1 frame than stall acquisition

### 5. **Process Isolation**
- **Problem**: Python GIL limits single-process performance
- **Solution**: True multiprocessing (separate OS processes)
- **Impact**: Acquisition runs at full speed regardless of consumers

---

## When to Use Which?

### Use Original `jq_glove_capture.py` when:
- ğŸ” Exploring the data format for the first time
- ğŸ› Debugging hardware/protocol issues
- ğŸ“Š Need detailed packet analysis and statistics
- ğŸ’¾ Creating test datasets for offline processing
- ğŸ“š Learning how the glove protocol works

### Use New `acquisition_process.py` when:
- ğŸ–¥ï¸ Building real-time GUI visualization
- ğŸ’¾ Continuous data logging (hours/days)
- ğŸŒŠ Streaming to LSL, OSC, or other systems
- ğŸ¯ Production applications (gesture recognition, VR, etc.)
- âš¡ Need maximum performance (200+ Hz)
- ğŸ”§ Multiple consumers (GUI + logger + streamer)

---

## Migration Path

If you have code using the original approach, here's how to migrate:

### Original Pattern
```python
# Old way: batch capture
ser = serial.Serial(port, 921600, timeout=1.0)
all_data = bytearray()

for duration:
    chunk = ser.read(ser.in_waiting)
    all_data.extend(chunk)

# Analyze after
packets = split_packets(all_data)
```

### New Pattern
```python
# New way: real-time stream
acq = AcquisitionProcess(port)
acq.start()

while running:
    frame_data = acq.get_frame(block=False)
    if frame_data:
        # Process immediately
        process_frame(frame_data['frame'])

acq.stop()
```

---

## Performance Summary

| Metric | Original | New | Improvement |
|--------|----------|-----|-------------|
| **Frame rate** | 10-20 Hz | 200+ Hz | **10-20x** |
| **Latency** | Seconds | <50ms | **40-100x** |
| **Read efficiency** | 103 B/read | 3217 B/read | **31x** |
| **CPU cores** | 1 | 2+ | **2x+** |
| **Memory** | 4 MB/min | 300 KB | **13x less** |

---

## Conclusion

The original `jq_glove_capture.py` was perfect for its purpose: **understanding the data**. It's simple, clear, and does exactly what it needs to do.

The new `acquisition_process.py` builds on those insights to create a **production-ready system** that can handle real-time applications at full hardware speed.

**They're complementary, not replacements:**
- Keep the original for exploration and debugging
- Use the new one for real-time applications

Both have their place in the toolkit! ğŸ› ï¸
